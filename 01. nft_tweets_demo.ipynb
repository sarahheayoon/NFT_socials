{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy as db\n",
    "import time\n",
    "\n",
    "nft_collection_df = pd.read_csv('eth_nft_30days.csv') #get sigdev nft rankings for the 30days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the csv. file to the right format\n",
    "for index, row in nft_collection_df.iterrows():\n",
    "    mystring =row['COLLECTION'].split(\">\",1)[1]\n",
    "    mystring = mystring.split(\"<\")[0]\n",
    "    mystring = mystring.replace(\"'\", \" \")\n",
    "    mystring = mystring.replace(\"[\", \" \")\n",
    "    mystring = mystring.replace(\"]\", \" \")\n",
    "    mystring = mystring.replace(\":\", \" \")\n",
    "    mystring = mystring.replace(\"  \", \" \")\n",
    "    mystring = mystring.replace(\" - \", \" \")\n",
    "\n",
    "    nft_collection_df.at[index, 'collection'] = mystring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out some nft collections\n",
    "nft_collection_df['collection'] = np.where((nft_collection_df.collection == 'Sandbox s LANDs'),'Sandbox Land',nft_collection_df.collection)\n",
    "nft_collection_df['collection'] = np.where((nft_collection_df.collection == 'Primera by Mitchell and Yun'),'Primera',nft_collection_df.collection)\n",
    "\n",
    "#not enough data for 0'clocks nft\n",
    "nft_collection_df.drop(nft_collection_df[nft_collection_df.collection == '7 O clock'].index, inplace = True)\n",
    "nft_collection_df.drop(nft_collection_df[nft_collection_df.collection == '3 O clock'].index, inplace = True)\n",
    "#sql error -  bind parameter\n",
    "nft_collection_df.drop(nft_collection_df[nft_collection_df.collection == 'Dci'].index, inplace = True) \n",
    "nft_collection_df.drop(nft_collection_df[nft_collection_df.collection == 'AK Ultra'].index, inplace = True) \n",
    "# twitter api data = 0 error {'meta': {'result_count': 0}}\n",
    "nft_collection_df.drop(nft_collection_df[nft_collection_df.collection == 'VOX Series 3'].index, inplace = True)\n",
    "nft_collection_df.drop(nft_collection_df[nft_collection_df.collection == 'Beeple Spring Collection'].index, inplace = True)\n",
    "nft_collection_df.drop(nft_collection_df[nft_collection_df.collection == 'Bored & Dangerous'].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "Could not parse rfc1738 URL from string ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cr/zjvbn6891vv75r_8rr4yfnfm0000gn/T/ipykernel_4984/767460817.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# step 1: connect to Postgres Socials Data/ Twitter API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mbearer_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;31m#twitter bearer token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/util/deprecations.py\u001b[0m in \u001b[0;36mwarned\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m                         \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                     )\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/create.py\u001b[0m in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;31m# create url.URL object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_instantiate_plugins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/url.py\u001b[0m in \u001b[0;36mmake_url\u001b[0;34m(name_or_url)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_parse_rfc1738_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mname_or_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/url.py\u001b[0m in \u001b[0;36m_parse_rfc1738_args\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m         raise exc.ArgumentError(\n\u001b[0m\u001b[1;32m    787\u001b[0m             \u001b[0;34m\"Could not parse rfc1738 URL from string '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         )\n",
      "\u001b[0;31mArgumentError\u001b[0m: Could not parse rfc1738 URL from string ''"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy as db\n",
    "import time\n",
    "import os\n",
    "\n",
    "# step 1: connect to Postgres Socials Data/ Twitter API\n",
    "engine = db.create_engine(\"\")\n",
    "connection = engine.connect()\n",
    "bearer_token = '' #twitter bearer token\n",
    "\n",
    "# step 2: get distinct collection names to track (split them up)\n",
    "nft_dict = dict(zip(nft_collection_df.collection, nft_collection_df.index))\n",
    "top_100_collections = list(nft_dict.keys())\n",
    "nested_top_100_collections = [top_100_collections[n:n+10] for n in range(0, len(top_100_collections), 10)] #splitting them up for twitter rate-limit\n",
    "\n",
    "# Twitter Query\n",
    "for i in range(len(nested_top_100_collections)): # paginating to account for twitter api rate limit \n",
    "    for item in nested_top_100_collections[i]:\n",
    "        # print(item)\n",
    "        headers = {'Authorization': f\"Bearer {bearer_token}\",}\n",
    "        params = {\n",
    "            'query': item + ' \"nft\" -is:retweet',\n",
    "            \"tweet.fields\": \"created_at,public_metrics,text\",\n",
    "            \"sort_order\": \"relevancy\",\n",
    "            \"max_results\": 100,\n",
    "            \"expansions\": \"author_id\",\n",
    "        }\n",
    "        response = requests.get('https://api.twitter.com/2/tweets/search/recent', params=params, headers=headers)\n",
    "        data = response.json()\n",
    "        data = pd.DataFrame(data['data'])\n",
    "        data = pd.concat([data.drop(['public_metrics'], axis=1), data['public_metrics'].apply(pd.Series)], axis=1)\n",
    "        result = data[['created_at', 'author_id', 'text','retweet_count', 'reply_count', 'like_count', 'id']]\n",
    "        result = result.replace('\\n',' ', regex=True)\n",
    "        result = result.replace(\"'\",\" \", regex=True)\n",
    "        result = result.replace(\"'s\", \" s\", regex=True)\n",
    "        \n",
    "        # making it into a string of tuple to insert sql command\n",
    "        s = ', '.join([\"(\"+ ', '.join( [\"'\" + item + \"'\", \"'\" + str(result.iloc[i].created_at)[0:19]+ \"'\",\n",
    "              \"'\"+str(result.iloc[i].author_id)+\"'\", \"'\"+str(result.iloc[i].text)+\"'\", \"'\" + str(result.iloc[i].retweet_count)+ \"'\", \"'\"+str(result.iloc[i].reply_count)+\"'\", \"'\"+str(result.iloc[i].like_count)+\"'\", \"'\"+str(result.iloc[i].id)+\"'\"+ \")\" ]) for i in range(len(result))])\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        INSERT INTO nft_tweets_demo \n",
    "        VALUES {s}\n",
    "        ON CONFLICT ON CONSTRAINT unique_tweet_id \n",
    "        DO NOTHING\n",
    "        \"\"\"\n",
    "        try:\n",
    "            pd.read_sql_query(db.text(query), connection)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            # print(item)\n",
    "\n",
    "    # print('---loop---')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 18:29:29) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2005b1c0606921f55dc9b8a725d797fe23931b11cf5bfe23322e3501bb52246b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
