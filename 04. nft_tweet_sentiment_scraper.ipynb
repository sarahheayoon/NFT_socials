{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mnft_tweets_demo2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrequests\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msqlalchemy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mdb\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# EC2 Code \n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy as db\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Step 1: Set up\n",
    "engine = db.create_engine(\"\")\n",
    "connection = engine.connect()\n",
    "bearer_token = ''\n",
    "\n",
    "nft_collection_df = pd.read_sql_query('select distinct(collection) from nft_tweets_demo2', connection)\n",
    "nft_dict = dict(zip(nft_collection_df.collection, nft_collection_df.index))\n",
    "top_100_collections = list(nft_dict.keys())\n",
    "nested_top_100_collections = [top_100_collections[n:n+4] for n in range(0, len(top_100_collections), 4)]\n",
    "\n",
    "# helper function to add account information later - left joining account info for tweets scraped (query2)\n",
    "def get_twitter_id_info(twitter_id: str):\n",
    "    \"\"\" purpose: get twitter account information\n",
    "    \"\"\"\n",
    "    response = requests.get(f'https://api.twitter.com/2/users?ids={twitter_id}&user.fields=public_metrics,username', headers=headers)\n",
    "    data = response.json()\n",
    "    try:\n",
    "        if bool(data['errors'][0]): # to account for deleted/suspended accounts\n",
    "            return(pd.DataFrame())\n",
    "    except:\n",
    "        pass\n",
    "    data = pd.DataFrame(data['data'])\n",
    "    data = pd.concat([data.drop(['public_metrics'], axis=1), data['public_metrics'].apply(pd.Series)], axis=1)\n",
    "    return data\n",
    "\n",
    "\n",
    "# Twitter Call \n",
    "for i in range(2,len(nested_top_100_collections)): # paginating to account for twitter api rate limit\n",
    "    time.sleep(900) # to account for rate limit\n",
    "    # step 1: getting relevant tweets for each collection\n",
    "    for item in nested_top_100_collections[i]:\n",
    "        headers = {'Authorization': f\"Bearer {bearer_token}\",}\n",
    "        params = {\n",
    "            'query': item + ' \"nft\" -is:retweet',\n",
    "            \"tweet.fields\": \"created_at,public_metrics,text\",\n",
    "            #\"sort_order\": \"relevancy\",\n",
    "            \"max_results\": 100,\n",
    "            \"expansions\": \"author_id\",\n",
    "        }\n",
    "        response = requests.get('https://api.twitter.com/2/tweets/search/recent', params=params, headers=headers)\n",
    "        data = response.json()\n",
    "        try:\n",
    "            data = pd.DataFrame(data['data'])\n",
    "        except:\n",
    "            pass\n",
    "        data = pd.concat([data.drop(['public_metrics'], axis=1), data['public_metrics'].apply(pd.Series)], axis=1)\n",
    "        result = data[['created_at', 'author_id', 'text','retweet_count', 'reply_count', 'like_count', 'id']]\n",
    "        result = result.replace('\\n',' ', regex=True)\n",
    "        result = result.replace(\"'\",\" \", regex=True)\n",
    "        result = result.replace(\"'s\", \" s\", regex=True)\n",
    "        \n",
    "        # making the result into a string of tuplees\n",
    "        s = ', '.join([\"(\"+ ', '.join( [\"'\" + item + \"'\", \"'\" + str(result.iloc[i].created_at)[0:19]+ \"'\",\n",
    "                \"'\"+str(result.iloc[i].author_id)+\"'\", \"'\"+str(result.iloc[i].text)+\"'\", \"'\" + str(result.iloc[i].retweet_count)+ \"'\", \"'\"+str(result.iloc[i].reply_count)+\"'\", \"'\"+str(result.iloc[i].like_count)+\"'\", \"'\"+str(result.iloc[i].id)+\"'\"+ \")\" ]) for i in range(len(result))])\n",
    "\n",
    "        # query 1 inserts all tweets relevant to each collection\n",
    "        query1 = f\"\"\"\n",
    "        INSERT INTO nft_tweets_demo2 \n",
    "        VALUES {s}\n",
    "        ON CONFLICT ON CONSTRAINT unique_tweet_id2 \n",
    "        DO \n",
    "            UPDATE SET retweet_count = EXCLUDED.retweet_count\n",
    "            UPDATE SET reply_count = EXCLUDED.retweet_count\n",
    "            UPDATE SET like_count = EXCLUDED.like_count;\n",
    "        \"\"\"\n",
    "        try:\n",
    "            pd.read_sql_query(db.text(query1), connection)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # step 2: retrieves distinct accounts for the tweets scraped above \n",
    "        id_list = result['author_id'].to_list()\n",
    "        id_list_final = list(set(id_list))\n",
    "\n",
    "        # step 3: adding account information to the table\n",
    "        for i in range(len(id_list_final)):\n",
    "            df2 = get_twitter_id_info(id_list_final[i])\n",
    "\n",
    "            if not df2.empty:\n",
    "                query2 = f\"\"\"\n",
    "                update nft_tweets_demo2 set username = '{df2.username.iloc[0]}', followers_count = '{df2.followers_count.iloc[0]}' where author_id = '{df2.id.iloc[0]}'\n",
    "                \"\"\"\n",
    "            try:\n",
    "                pd.read_sql_query(query2, connection)\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "time.sleep(18000) #every 5hr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Sep 26 2022, 11:37:49) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
